apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: telegraf
  namespace: kube-system
spec:
  chart: telegraf-ds
  repo: https://helm.influxdata.com/
  targetNamespace: monitoring
  version: 1.1.34
  valuesContent: |-
    ## Environment
    env:
      - name: NODE_IP
        valueFrom:
          fieldRef:
            fieldPath: status.hostIP
      # This pulls HOSTNAME from the node, not the pod.
      - name: HOSTNAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      # Mount the host filesystem and set the appropriate env variables.
      # ref: https://github.com/influxdata/telegraf/blob/master/docs/FAQ.md
      # HOST_PROC is required by the cpu, disk, diskio, kernel and processes input plugins
      - name: "HOST_PROC"
        value: "/hostfs/proc"
      # HOST_SYS is required by the diskio plugin
      - name: "HOST_SYS"
        value: "/hostfs/sys"
      - name: "HOST_MOUNT_PREFIX"
        value: "/hostfs"

    envFromSecret: "sec-influxdb"
    rbac:
      create: false

    override_config:
      toml: ~
      toml: |+
        [agent]
          collection_jitter = "0s"
          debug = false
          flush_interval = "60s"
          flush_jitter = "10s"
          hostname = "$HOSTNAME"
          interval = "20s"
          logfile = ""
          metric_batch_size = 1000
          metric_buffer_limit = 10000
          omit_hostname = false
          precision = ""
          quiet = false
          round_interval = true

        [[inputs.diskio]]
        [[inputs.kernel]]
        [[inputs.mem]]
        [[inputs.net]]
        [[inputs.processes]]
        [[inputs.swap]]
        [[inputs.system]]

        [[inputs.cpu]]
        percpu = true
        totalcpu = true
        collect_cpu_time = false
        report_active = false

        [[inputs.disk]]
        ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs", "nsfs"]
        # [[inputs.docker]]
        # endpoint = "unix:///var/run/docker.sock"

        # Disk monitoring using S.M.A.R.T
        [[inputs.smartctl]]
        path = "$HOST_MOUNT_PREFIX/usr/bin/smartctl"
        interval = "30m"

        [[inputs.kubernetes]]
        url = "https://$NODE_IP:10250"
        bearer_token = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        insecure_skip_verify = true

        [[inputs.kube_inventory]]
        url = "https://$NODE_IP:6443"
        bearer_token = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        insecure_skip_verify = true
        namespace = ""
        resource_include = [ "deployments", "pods", "statefulsets", "daemonsets" ]

        # Pods' Prometheus metrics source
        [[inputs.prometheus]]
        ## An array of urls to scrape metrics from.
        # urls = ["http://traefik-internal.traefik.svc:9100/metrics"]
        monitor_kubernetes_pods = true
        pod_scrape_scope = "node"

        pod_label_include = ["app.kubernetes.io/component", "app.kubernetes.io/instance", "app.kubernetes.io/name", "app"]
        pod_annotation_include = []
 
        url_tag = "metrics_url"
        namedrop = ["go_*"]

        ## Rclone metrics source
        [[inputs.prometheus]]
        ## An array of urls to scrape metrics from.
        urls = ["http://$NODE_IP:5572/metrics"]
        # Rclone authentication
        username = "admin"
        password = "rclone"

        [global_tags]
          Instance = "Pi"

        [[outputs.influxdb_v2]]
          urls           = ["https://eu-central-1-1.aws.cloud2.influxdata.com/"]
          token          = "$INFLUXDB_TOKEN"
          bucket         = "metrics"
          organization   = "TheFaker"

# securityContext:
#         privileged: true
